{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b2c75b4",
   "metadata": {},
   "source": [
    "# Codificador y Decodificador en video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2f8c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "from scipy.signal import firwin, lfilter, get_window\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.io import wavfile as wav\n",
    "from vozyaudio import lee_audio, sonido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0329150",
   "metadata": {},
   "source": [
    "## Codificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelSoundsEncoder:\n",
    "    \"\"\"\n",
    "    Convierte un audio en un “vídeo pixelado” codificando cada bloque de\n",
    "    muestras en filas de imágenes.\n",
    "\n",
    "    - Primer frame: metadatos (N, hop, fps, modo color).\n",
    "    - Siguientes frames: bloques de audio coloreados (gris o RGB).\n",
    "    - Luego empaqueta PNGs en MP4 con un batch externo.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_path,\n",
    "        frames_dir=\"fotogramas\",\n",
    "        export_dir=\"exports\",\n",
    "        fps=60,\n",
    "        color_mode=\"color\",   # 'gris' o 'color'\n",
    "        map_mode=\"ampl\",       # 'ampl', 'fft' o 'fir'\n",
    "        window_type=\"hann\",\n",
    "        numcoef=101\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inicializa el codificador con:\n",
    "\n",
    "        audio_path   : ruta al WAV de entrada.\n",
    "        frames_dir   : carpeta donde escribir PNGs.\n",
    "        export_dir   : carpeta de salida de vídeo.\n",
    "        fps          : frames por segundo del vídeo.\n",
    "        color_mode   : 'gris' o 'color'.\n",
    "        map_mode     : 'ampl', 'fft' o 'fir'.\n",
    "        window_type  : tipo de ventana (p.ej. 'hann').\n",
    "        numcoef      : coeficientes FIR (solo para 'fir').\n",
    "        \"\"\"\n",
    "        self.audio_path  = audio_path\n",
    "        self.frames_dir  = frames_dir\n",
    "        self.export_dir  = export_dir\n",
    "        self.fps         = fps\n",
    "        self.color_mode  = color_mode\n",
    "        self.map_mode    = map_mode\n",
    "        self.window_type = window_type\n",
    "        # Flag para modo color: 0=gris, 1=color\n",
    "        self.iscolor     = 1 if color_mode == \"color\" else 0\n",
    "\n",
    "        # Leer y normalizar audio de 16-bit\n",
    "        self.fs, audio = lee_audio(audio_path)\n",
    "        self.audio     = audio.astype(np.float32)\n",
    "        self.audio    /= np.max(np.abs(self.audio)) + 1e-12\n",
    "\n",
    "        # Diseñar filtros FIR (baja, banda, alta)\n",
    "        self.b_low  = firwin(numcoef, cutoff=2000,                   fs=self.fs)\n",
    "        self.b_band = firwin(numcoef, [2000, 6000], pass_zero=False, fs=self.fs)\n",
    "        self.b_high = firwin(numcoef, cutoff=6000, pass_zero=False,  fs=self.fs)\n",
    "\n",
    "        # Preparar directorios de salida\n",
    "        if os.path.exists(self.frames_dir):\n",
    "            shutil.rmtree(self.frames_dir)\n",
    "        os.makedirs(self.frames_dir, exist_ok=True)\n",
    "        os.makedirs(self.export_dir, exist_ok=True)\n",
    "\n",
    "    def _write_header(self, N, hop):\n",
    "        # Creamos un frame cuadrado de tamaño N×N\n",
    "        header = np.zeros((N, N), dtype=np.uint8)\n",
    "\n",
    "        # Desglosar N y hop en bytes altos y bajos\n",
    "        hiN, loN = (N >> 8) & 0xFF, N & 0xFF\n",
    "        hiH, loH = (hop >> 8) & 0xFF, hop & 0xFF\n",
    "        b_fps     = self.fps & 0xFF\n",
    "\n",
    "        # Filas 0–4: hiN, loN, hiH, loH, fps\n",
    "        header[0, :] = hiN\n",
    "        header[1, :] = loN\n",
    "        header[2, :] = hiH\n",
    "        header[3, :] = loH\n",
    "        header[4, :] = b_fps\n",
    "\n",
    "        # Fila 5: modo de imagen (0=gris, 1=color)\n",
    "        header[5, :] = self.iscolor\n",
    "\n",
    "        # Guardar encabezado como primer frame PNG\n",
    "        path = os.path.join(self.frames_dir, \"frame_0000.png\")\n",
    "        imageio.imwrite(path, header)\n",
    "\n",
    "    def _colorear_fila(self, fila, modo):\n",
    "        \"\"\"\n",
    "        Dada una fila (uint8) y el modo, devuelve Nx3 RGB uint8 coloreado.\n",
    "        \"\"\"\n",
    "        # fila puede ser (N,) o (N,3)\n",
    "        if modo == 'ampl':\n",
    "            # fila: (N,) uint8\n",
    "            amp = fila\n",
    "            r = amp\n",
    "            g = 255 - amp\n",
    "            b = 128 * np.ones_like(amp, dtype=np.uint8)\n",
    "        elif modo == 'fft':\n",
    "            # fila_fft: (N,2) uint8 con [mag_n, phase_n]\n",
    "            mag_n, phase_n = fila[:,0], fila[:,1]\n",
    "\n",
    "            # Propuesta: R=mag_n, G=phase_n, B=255\n",
    "            r = mag_n\n",
    "            g = phase_n\n",
    "            b = 255 * np.ones_like(r, dtype=np.uint8)\n",
    "        elif modo == \"fir\":\n",
    "            # fila ya es Nx3 con low, band, high\n",
    "            r = fila[:,0]\n",
    "            g = fila[:,1]\n",
    "            b = fila[:,2]\n",
    "        else:\n",
    "            raise ValueError(f\"Modo desconocido para colorear: {modo}\")\n",
    "\n",
    "        # Apilar y asegurar uint8\n",
    "        return np.stack([r, g, b], axis=1).astype(np.uint8)\n",
    "\n",
    "    def generate_frames(self):\n",
    "        # Determinar N según fs/fps y asegurar paridad\n",
    "        N = self.fs // self.fps\n",
    "        if N % 2: N += 1\n",
    "        hop = N // 2\n",
    "\n",
    "        # Escribir primer frame con metadata\n",
    "        self._write_header(N, hop)\n",
    "\n",
    "        # Ventana y número de bloques\n",
    "        window   = get_window(self.window_type, N)\n",
    "        n_blocks = (len(self.audio) - N) // hop\n",
    "        print(f\"N={N}, HOP={hop}, FPS={self.fps}, Bloques={n_blocks}\")\n",
    "\n",
    "        # Para cada bloque, crear frame y guardarlo\n",
    "        for i in range(n_blocks):\n",
    "            start = i * hop\n",
    "            block = self.audio[start:start+N] * window\n",
    "\n",
    "            # 1) Construir fila base según map_mode\n",
    "            if self.map_mode == \"ampl\":\n",
    "                norm = (block - block.min()) / (block.max() - block.min() + 1e-12)\n",
    "\n",
    "                # FILA\n",
    "                fila = (norm * 255).astype(np.uint8)              # (N,)\n",
    "\n",
    "            elif self.map_mode == \"fft\":\n",
    "                # FFT + shift (centrar DC)\n",
    "                X      = fft(block, n=N)\n",
    "                X      = np.fft.fftshift(X)\n",
    "                mag    = np.abs(X)\n",
    "                phase  = np.angle(X)\n",
    "\n",
    "                # Normalizar magnitud y fase a rango 0–255\n",
    "                mag_n   = np.round((mag   / (mag.max() + 1e-12)) * 255).astype(np.uint8)\n",
    "                phase_n = np.round(((phase + np.pi) / (2*np.pi)) * 255).astype(np.uint8)\n",
    "\n",
    "                # Fila base: [mag_n, phase_n, canal vacío]\n",
    "                fila    = np.stack([mag_n, phase_n, np.zeros_like(mag_n)], axis=1)  # (N,3)\n",
    "\n",
    "            elif self.map_mode == \"fir\":\n",
    "                # Aplicamos filtros\n",
    "                y_l = lfilter(self.b_low,  1.0, block)\n",
    "                y_b = lfilter(self.b_band, 1.0, block)\n",
    "                y_h = lfilter(self.b_high, 1.0, block)\n",
    "                \n",
    "                # Para que se mantenga entre -1 y +1\n",
    "                y_l, y_b, y_h = map(lambda y: np.clip(y, -1, 1), (y_l,y_b,y_h))\n",
    "\n",
    "                # Normalizamos a 8 bits\n",
    "                r8 = np.round(y_l*127).astype(np.int8).view(np.uint8)\n",
    "                g8 = np.round(y_b*127).astype(np.int8).view(np.uint8)\n",
    "                b8 = np.round(y_h*127).astype(np.int8).view(np.uint8)\n",
    "\n",
    "                # FILA\n",
    "                fila = np.stack([r8, g8, b8], axis=1)         # (N,3)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"map_mode debe ser 'ampl', 'fft' o 'fir'\")\n",
    "\n",
    "            # 2) Colorear o replicar según color_mode\n",
    "            if self.color_mode == \"gris\":\n",
    "                # replicar fila en 3 capas idénticas\n",
    "                gris = fila if fila.ndim==1 else fila[:,0]\n",
    "                img  = np.tile(gris[np.newaxis,:], (N,1))\n",
    "            else:\n",
    "                base_rgb = fila if fila.ndim==2 else np.stack([fila]*3,axis=1)\n",
    "                colored  = self._colorear_fila(base_rgb, self.map_mode)\n",
    "                img      = np.tile(colored[np.newaxis,...], (N,1,1))\n",
    "\n",
    "            # Guardar PNG\n",
    "            path = os.path.join(self.frames_dir, f\"frame_{i+1:04d}.png\")\n",
    "            imageio.imwrite(path, img)\n",
    "\n",
    "        print(f\"[Encoder] Generados {n_blocks} fotogramas en '{self.frames_dir}/'\")\n",
    "\n",
    "    def encode_video(self, output_name=None):\n",
    "        # Nombre de salida\n",
    "        base = os.path.splitext(os.path.basename(self.audio_path))[0]\n",
    "        name = output_name or f\"{base}_{self.map_mode}_{self.color_mode}.mp4\"\n",
    "        out  = os.path.join(self.export_dir, name)\n",
    "        if os.path.exists(out):\n",
    "            os.remove(out)\n",
    "\n",
    "        # Llamada externa para empaquetar en MP4\n",
    "        subprocess.run(\n",
    "            [\"cmd\", \"/c\", \"generarVideo2.bat\", str(self.fps), out],\n",
    "            check=True\n",
    "        )\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7c1d7",
   "metadata": {},
   "source": [
    "## Decodificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df767272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelSoundsDecoder:\n",
    "    \"\"\"\n",
    "    Decodifica un vídeo generado por PixelSoundsEncoder de vuelta a WAV.\n",
    "\n",
    "    - Primer frame: metadatos (N, hop, fps, color_mode).\n",
    "    - Siguientes frames: bloques de audio (gris o RGB) codificados.\n",
    "    - Reconstruye por overlap-add y guarda WAV.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        frames_dir,\n",
    "        output_wav,\n",
    "        map_mode='ampl',    # 'ampl', 'fft' o 'fir'\n",
    "        window_type='hann'  # tipo de ventana para overlap-add\n",
    "    ):\n",
    "        self.frames_dir   = frames_dir\n",
    "        self.output_wav   = output_wav\n",
    "        self.map_mode     = map_mode\n",
    "        self.window_type  = window_type\n",
    "\n",
    "        # preparar carpeta limpia para extraer frames\n",
    "        if os.path.exists(frames_dir):\n",
    "            shutil.rmtree(frames_dir)\n",
    "        os.makedirs(self.frames_dir, exist_ok=True)\n",
    "\n",
    "    def extract_all_frames(self, video_path, prefix=\"frame_\", fmt=\"png\"):\n",
    "        print(f\"[Decoder] Extrayendo frames de '{video_path}'...\")\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"No se pudo abrir el vídeo {video_path}\")\n",
    "        idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            fname = f\"{prefix}{idx:04d}.{fmt}\"\n",
    "            cv2.imwrite(os.path.join(self.frames_dir, fname), frame)\n",
    "            idx += 1\n",
    "        cap.release()\n",
    "        print(f\"[Decoder] Total frames extraídos: {idx}\")\n",
    "        return idx\n",
    "\n",
    "    def extraer_metadatos_cabecera_rows(self, frame):\n",
    "        print(\"[Decoder] Leyendo metadatos de header...\")\n",
    "        # forzar uint8 y extraer canal único\n",
    "        if frame.dtype != np.uint8:\n",
    "            frame = np.clip(frame * 255, 0, 255).astype(np.uint8)\n",
    "        if frame.ndim == 3:\n",
    "            frame = frame[..., 0]\n",
    "\n",
    "        # filas 0–1: N (hi, lo)\n",
    "        hiN, loN = int(frame[0,0]), int(frame[1,0])\n",
    "        # filas 2–3: hop (hi, lo)\n",
    "        hiH, loH = int(frame[2,0]), int(frame[3,0])\n",
    "        # fila 4: fps\n",
    "        fps      = int(frame[4,0])\n",
    "        # fila 5: modo color (0=gris, 1=color)\n",
    "        flag     = int(frame[5,0])\n",
    "\n",
    "        N        = (hiN << 8) | loN\n",
    "        hop      = (hiH << 8) | loH\n",
    "        is_color = bool(flag)\n",
    "\n",
    "        print(f\"[Decoder] Header -> N={N}, hop={hop}, fps={fps}, modo={'color' if is_color else 'gris'}\")\n",
    "        return N, hop, fps, is_color\n",
    "\n",
    "    def decode(self):\n",
    "        \"\"\"\n",
    "        Reconstruye el audio a partir de los PNG ya extraídos en self.frames_dir.\n",
    "        Asume que frame_0000.png (header) y los frames de datos están presentes.\n",
    "        \"\"\"\n",
    "        # 1) Leer y parsear header (frame_0000.png)\n",
    "        frame0    = imageio.imread(os.path.join(self.frames_dir, \"frame_0000.png\"))\n",
    "        N, hop, fps, self.is_color = self.extraer_metadatos_cabecera_rows(frame0)\n",
    "        fs_recon  = N * fps   # fs = muestras por frame × frames por segundo\n",
    "\n",
    "        # 2) Listar solo los archivos de datos\n",
    "        files     = sorted(f for f in os.listdir(self.frames_dir)\n",
    "                           if f.startswith(\"frame_\") and f != \"frame_0000.png\")\n",
    "        n_blocks  = len(files)\n",
    "        print(f\"[Decoder] Frames de datos: {n_blocks}\")\n",
    "\n",
    "        # 3) Preparar buffers para overlap-add\n",
    "        length    = N + hop * (n_blocks - 1)\n",
    "        audio     = np.zeros(length, dtype=np.float32)\n",
    "        pesos     = np.zeros(length, dtype=np.float32)\n",
    "        ventana   = get_window(self.window_type, N)\n",
    "        print(f\"[Decoder] Ventana '{self.window_type}' aplicada, primeros valores: {ventana[:5]}\")\n",
    "\n",
    "        # 4) Reconstruir bloque a bloque\n",
    "        for i, fname in enumerate(files, start=1):\n",
    "            print(f\"[Decoder] Procesando block {i}/{n_blocks}: {fname}\")\n",
    "            img = imageio.imread(os.path.join(self.frames_dir, fname)).astype(np.float32) / 255.0\n",
    "            row = img[0]    # primera fila de pixeles: shape (N,3)\n",
    "\n",
    "            if not self.is_color:\n",
    "                # → modo gris: colapsar los 3 canales (idénticos) a 1D\n",
    "                gris  = row[:, 0]\n",
    "                pix   = gris\n",
    "                print(f\"[Decoder]  gris block, primeros pix: {pix[:5]}\")\n",
    "\n",
    "                if self.map_mode != 'ampl':\n",
    "                    raise ValueError(\"En modo gris solo map_mode='ampl'\")\n",
    "                \n",
    "                \n",
    "                # restaurar amplitud lineal: [0→1] → [-1→+1]\n",
    "                block = pix * 2 - 1\n",
    "                print(f\"[Decoder]  ampl(gris) block, primeros 5 samples: {block[:5]}\")\n",
    "            else:\n",
    "                # → modo color: row es Nx3\n",
    "                pix = row\n",
    "                print(f\"[Decoder]  color block, pix.shape = {pix.shape}, primeros pix: {pix[:3]}\")\n",
    "                if self.map_mode == 'ampl':\n",
    "                    # reconstruir amplitud 24-bit\n",
    "                    hi   = pix[:,0].astype(np.uint32)\n",
    "                    md   = pix[:,1].astype(np.uint32)\n",
    "                    lo   = pix[:,2].astype(np.uint32)\n",
    "                    X24  = (hi<<16)|(md<<8)|lo\n",
    "                    block = (X24/(2**24-1))*2 - 1\n",
    "                    print(f\"[Decoder]  ampl block, primeros 5 samples: {block[:5]}\")\n",
    "                elif self.map_mode == 'fft':\n",
    "                    # reconstruir FFT con magnitud y fase\n",
    "                    mag_n   = pix[:,0]\n",
    "                    phase_n = pix[:,1]\n",
    "                    phase   = phase_n * 2*np.pi - np.pi\n",
    "                    X       = mag_n * np.exp(1j * phase)\n",
    "                    # revertir el fftshift aplicado en el encoder\n",
    "                    X       = np.fft.ifftshift(X)\n",
    "                    block   = np.real(ifft(X, n=N))\n",
    "                    print(f\"[Decoder]  fft block, primeros 5 samples: {block[:5]}\")\n",
    "                elif self.map_mode == 'fir':\n",
    "                    # reinterpretar int8 en float\n",
    "                    r8    = pix[:,0].view(np.int8).astype(np.float32) / 127.0\n",
    "                    block = r8\n",
    "                    print(f\"[Decoder]  fir block, primeros 5 samples: {block[:5]}\")\n",
    "                else:\n",
    "                    raise ValueError(\"map_mode debe ser 'ampl', 'fft' o 'fir'\")\n",
    "\n",
    "            # 5) Overlap-add con ventana\n",
    "            start = (i-1) * hop\n",
    "            audio[start:start+N] += block * ventana\n",
    "            pesos[start:start+N] += ventana\n",
    "            if i == 1:\n",
    "                print(f\"[Decoder]  overlap-add i=1, audio[0:5]={audio[0:5]}\")\n",
    "\n",
    "        # 6) Normalizar todo el audio\n",
    "        print(f\"[Decoder] Antes normalización, min/max = {audio.min():.4f}/{audio.max():.4f}\")\n",
    "        audio /= (pesos + 1e-12)\n",
    "        print(f\"[Decoder] Después normalización, min/max = {audio.min():.4f}/{audio.max():.4f}\")\n",
    "\n",
    "        # 7) Reproducir y guardar WAV\n",
    "        sonido(audio, fs_recon)\n",
    "\n",
    "        # Asegurar carpeta de salida y renombrar con modo y color\n",
    "        out_dir = os.path.dirname(self.output_wav) or '.'\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        base       = os.path.splitext(os.path.basename(self.output_wav))[0]\n",
    "        mode_color = 'color' if self.is_color else 'gris'\n",
    "        new_name   = f\"{base}_{self.map_mode}_{mode_color}_recon.wav\"\n",
    "        out_path   = os.path.join(out_dir, new_name)\n",
    "\n",
    "        # Escalar a 16-bit y escribir WAV\n",
    "        scaled = np.int16(np.clip(audio, -1, 1) * 32767)\n",
    "        wav.write(out_path, fs_recon, scaled)\n",
    "        print(f\"[Decoder] WAV reconstruido en: {out_path} ({fs_recon} Hz)\")\n",
    "\n",
    "        return audio, fs_recon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304a98e",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b53690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_metadatos_cabecera_rows(frame):\n",
    "    \"\"\"\n",
    "    Extrae N, salto y fps de un array 2D o 3D codificado por filas:\n",
    "    fila 0→hiN, 1→loN, 2→hiS, 3→loS, 4→fps.\n",
    "    \"\"\"\n",
    "    # asegurar uint8 y escala de grises\n",
    "    if frame.dtype != np.uint8:\n",
    "        frame = np.clip(frame * 255, 0, 255).astype(np.uint8)\n",
    "    if frame.ndim == 3:\n",
    "        frame = frame[..., 0]\n",
    "\n",
    "    hiN  = int(frame[0, 0]);     loN  = int(frame[1, 0])\n",
    "    hiS  = int(frame[2, 0]);     loS  = int(frame[3, 0])\n",
    "    fpsb = int(frame[4, 0])\n",
    "\n",
    "    N     = (hiN << 8) + loN\n",
    "    salto = (hiS << 8) + loS\n",
    "    fps   = fpsb\n",
    "\n",
    "    return N, salto, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def borrar_carpetas():\n",
    "    try:\n",
    "        shutil.rmtree(\"fotogramas\")\n",
    "        shutil.rmtree(\"decoded\")\n",
    "        shutil.rmtree(\"exports\")\n",
    "    finally:\n",
    "        print(\"borradas\")\n",
    "borrar_carpetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b75806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original → N: 736, salto: 368, fps: 60\n"
     ]
    }
   ],
   "source": [
    "ruta_frame = os.path.join(\"fotogramas\", \"frame_0000.png\")\n",
    "frame_orig = imageio.imread(ruta_frame)\n",
    "\n",
    "# Extrae y muestra los metadatos\n",
    "N, salto, fps = extraer_metadatos_cabecera_rows(frame_orig)\n",
    "print(f\"Original → N: {N}, salto: {salto}, fps: {fps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffb5b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original → N: 736, salto: 368, fps: 61\n"
     ]
    }
   ],
   "source": [
    "ruta_frame = os.path.join(\"analisis\", \"frame_0000.png\")\n",
    "frame_orig = imageio.imread(ruta_frame)\n",
    "\n",
    "# Extrae y muestra los metadatos\n",
    "N, salto, fps = extraer_metadatos_cabecera_rows(frame_orig)\n",
    "print(f\"Original → N: {N}, salto: {salto}, fps: {fps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc8fe1",
   "metadata": {},
   "source": [
    "## Codificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4204a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al WAV de entrada\n",
    "audio_path = \"audios/music.wav\"\n",
    "# Carpeta donde se volcarán los PNG\n",
    "frames_dir = \"fotogramas\"\n",
    "# Carpeta donde se guardará el MP4 final\n",
    "export_dir = \"exports\"\n",
    "\n",
    "# Parámetros de codificación\n",
    "fps         = 60          # frames por segundo\n",
    "color_mode  = \"color\"     # \"gris\" o \"color\"\n",
    "map_mode    = \"fft\"       # \"ampl\", \"fft\" o \"fir\"\n",
    "window_type = \"hann\"      # tipo de ventana para framing\n",
    "numcoef     = 101         # n° de coef. FIR (solo importa para 'fir')\n",
    "\n",
    "\n",
    "encoder = PixelSoundsEncoder(\n",
    "    audio_path=audio_path,\n",
    "    frames_dir=frames_dir,\n",
    "    export_dir=export_dir,\n",
    "    fps=fps,\n",
    "    color_mode=color_mode,\n",
    "    map_mode=map_mode,\n",
    "    window_type=window_type,\n",
    "    numcoef=numcoef\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d95b09b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=736, HOP=368, FPS=60, Bloques=1196\n",
      "[Encoder] Generados 1196 fotogramas en 'fotogramas/'\n",
      "[Encoder] Frames generados en 'fotogramas/'\n",
      "[Encoder] Vídeo exportado en 'exports\\music_fft_color.mp4'\n"
     ]
    }
   ],
   "source": [
    "# 2) Generar los PNG\n",
    "encoder.generate_frames()\n",
    "print(f\"[Encoder] Frames generados en '{frames_dir}/'\")\n",
    "\n",
    "# 3) Empaquetar los frames en un MP4\n",
    "video_file = encoder.encode_video()\n",
    "print(f\"[Encoder] Vídeo exportado en '{video_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667b38b",
   "metadata": {},
   "source": [
    "## Decodificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "41be9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path  = os.path.join(\"exports\", \"music_fir_color.mp4\")   # mp4 generado por el encoder\n",
    "frames_dir  = \"analisis\"                                    \n",
    "output_wav  = os.path.join(\"exports\", \"music_recon.wav\")      # WAV reconstruido\n",
    "map_mode    = \"fir\"                                          # debe coincidir con encoder\n",
    "window_type = \"hann\"                                          # idem\n",
    "\n",
    "# 2) Instanciar el decoder\n",
    "decoder = PixelSoundsDecoder(\n",
    "    frames_dir=frames_dir,\n",
    "    output_wav=output_wav,\n",
    "    map_mode=map_mode,\n",
    "    window_type=window_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "89b8647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decoder] Extrayendo frames de 'exports\\music_fir_color.mp4'...\n",
      "[Decoder] Total frames extraídos: 1197\n",
      "[Decoder] Extraídos 1197 fotogramas en 'analisis/'\n"
     ]
    }
   ],
   "source": [
    "# 3) Extraer todos los fotogramas del vídeo\n",
    "total = decoder.extract_all_frames(video_path)\n",
    "print(f\"[Decoder] Extraídos {total} fotogramas en '{frames_dir}/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "41375268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Decoder] Leyendo metadatos de header...\n",
      "[Decoder] Header -> N=736, hop=368, fps=61, modo=color\n",
      "[Decoder] Frames de datos: 1196\n",
      "[Decoder] Ventana 'hann' aplicada, primeros valores: [0.00000000e+00 1.82197108e-05 7.28775154e-05 1.63969430e-04\n",
      " 2.91488817e-04]\n",
      "[Decoder] Procesando block 1/1196: frame_0001.png\n",
      "[Decoder]  color block, pix.shape = (736, 3), primeros pix: [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "To change to a dtype of a different size, the last axis must be contiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 4) Reconstruir el audio y guardar el WAV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m audio, fs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Decoder] Audio reconstruido (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz) guardado en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_wav\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[153], line 130\u001b[0m, in \u001b[0;36mPixelSoundsDecoder.decode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Decoder]  fft block, primeros 5 samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblock[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfir\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# reinterpretar int8 en float\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     r8    \u001b[38;5;241m=\u001b[39m \u001b[43mpix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m127.0\u001b[39m\n\u001b[0;32m    131\u001b[0m     block \u001b[38;5;241m=\u001b[39m r8\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Decoder]  fir block, primeros 5 samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblock[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: To change to a dtype of a different size, the last axis must be contiguous"
     ]
    }
   ],
   "source": [
    "# 4) Reconstruir el audio y guardar el WAV\n",
    "audio, fs = decoder.decode()\n",
    "print(f\"[Decoder] Audio reconstruido ({fs} Hz) guardado en '{output_wav}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Voz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
