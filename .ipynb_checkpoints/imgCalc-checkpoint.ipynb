{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto PixelSounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo\n",
    "La misión de este proyecto es crear un algoritmo capaz de crear, a partir de una imagen dada, un archivo de audio generado a través de cierto análisis a esta.\n",
    "\n",
    "Existen muchos parametros y operaciones con las que podemos extraer información que defina a una imagen; la solución más inmediata al problema es entonces usar estas como generadoras de las características de un posible sonido como resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scipy.fftpack as fft\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d, median_filter\n",
    "from scipy import signal\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    import vozyaudio as vz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De momento, ¿qué extraer de las entradas?\n",
    "- Las distintas representaciones de la imagen (RGB, YcBcR) y canales de estas\n",
    "- Componentes frecuenciale (DFT), aunque sería interesante otros tipos de transformada (DCT por ejemplo) con las que extraer otras componentes\n",
    "- Gradiente (derivada o diferencias entre los valores de los píxeles) tanto vertical como horizontal\n",
    "- Selección de valores concretos de los píxeles (colores o valores de brillo específicos)\n",
    "- Operaciones geométricas a la imagen\n",
    "- Histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rgb(input_img):\n",
    "    \"\"\"\n",
    "    Esta función debe recibir una imagen y separarla en sus 3 canales RGB.\n",
    "    Devolverá 3 matrices de mismo ancho y alto que la de entrada.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(input_img,cv2.IMREAD_COLOR)\n",
    "    b,g,r = cv2.split(img)\n",
    "    return r, g, b\n",
    "\n",
    "def extract_y(input_img):\n",
    "    \"\"\"\n",
    "    Extrae la matriz de brillo de la imagen entrante.\n",
    "    Devolverá 1 MATRIZ de mismo ancho y alto que la de entrada.\n",
    "    \"\"\"\n",
    "    y = cv2.imread(input_img, cv2.IMREAD_GRAYSCALE)\n",
    "    return y\n",
    "\n",
    "def extract_ycbcr(input_img):\n",
    "    \"\"\"\n",
    "    Esta función debe recibir una imagen y separarla en sus 3 canales YcBcR.\n",
    "    Devolverá 3 matrices de mismo ancho y alto que la de entrada.\n",
    "    \"\"\"\n",
    "    BGRImage = cv2.imread(imageName)\n",
    "    YCrCbImage = cv2.cvtColor(BGRImage, cv2.COLOR_BGR2YCR_CB)\n",
    "    y, cb, cr = cv2.split(YCrCbImage)\n",
    "    return y, cb, cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre el histograma de una imagen\n",
    "\n",
    "El histograma es un gráfico que nos ayuda a ver cómo están repartidos los niveles de brillo en los canales de una imagen. De normal puede ser útil para ver el nivel de contraste o si está sub- o sobre- expuesta. Sin embargo, ¿cómo podríamos aprovecharlo para nuestro objetivo? \n",
    "\n",
    "Una idea podía ser crear señales de audio a partir de este, ya que algunos histogramas de imágenes tienen parecido con algunos de audio, aunque salvando ciertas diferencias. Se pueden ver picos máximos parecidos a los que aparecen sobre el nivel 0 en audio y algunas distribuciones podrían parecerse a la geométrica, sin embargo esta es una operación no invertible, y aunque nos pueda dar información sobre los niveles que podría tener el sonido, no sabemos cómo distribuir estos.\n",
    "\n",
    "No habría que abandonar al 100% este camino, pero habría que darle una vuelta para poder aprovecharlo.\n",
    "\n",
    "Otra posibilidad es, y a esta le veo más futuro, poder asociar el uso de efectos a ciertas partes o toda la señal sonora en base al histograma de alguno o todos sus canales de color. Por ejemplo, si se dividiera el histograma del brillo de la imagen en ciertos rangos y donde cayera cierto porcentaje de píxeles en este aplicar de una forma u otra ciertos efectos.\n",
    "\n",
    "Ejemplo: analizando el histograma de brillo de un bloque de una imagen dada se ha visto que el 60% de todos los píxeles tienen un valor entre 0 y 50 de brillo. Esto provocará que a ese bloque de la imagen se le aplique un efecto de eco múltiple con 3 repeticiones, retardadas 0.3, 0.5 y 0.7 segundos y amplitudes indirectas 0.5, 0.3, y 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma(input_img):\n",
    "    \"\"\"\n",
    "    Recibe una imagen con 1 o más canales y devuelve el histograma de esta\n",
    "    Por hacer\n",
    "    \"\"\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformada de Fourier en una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_imagen_fft(ruta_imagen, fs, N=50,duracion=5):\n",
    "    \n",
    "    # Se lee y se aplana la imagen se pasa a gris para q los valores sean de 0 a 255\n",
    "    imagen = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "    imagen = cv2.resize(imagen, (256, 256))\n",
    "    valores_pixeles = imagen.flatten()\n",
    "    \n",
    "    # Se aplica la transformada de fourier para obtener las frecuencias (gracias Victor)\n",
    "    espectro = np.abs(fft.fft(valores_pixeles))\n",
    "    freqs = fft.fftfreq(len(valores_pixeles), d=1/fs)\n",
    "    \n",
    "    # se eliminan las frecuencias negativas\n",
    "    freqs = freqs[freqs > 0]\n",
    "    espectro = espectro[:len(freqs)]\n",
    "    \n",
    "    # se sacan las frecuencias principales\n",
    "    indices_principales = np.argsort(espectro)[-N:]\n",
    "    freqs_principales = freqs[indices_principales]\n",
    "    \n",
    "    # Se genera la señal de audio, se hace asi por la funcion de voz \n",
    "    t = np.linspace(0, duracion, int(fs * duracion), endpoint=False)\n",
    "    audio = np.zeros_like(t)\n",
    "    \n",
    "    for f in freqs_principales:\n",
    "        audio += np.sin(2 * np.pi * f * t)\n",
    "    \n",
    "    # se normaliza la señal\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    \n",
    "    vz.sonido(audio, fs)\n",
    "    \n",
    "    plt.plot(t[:1000], audio[:1000],label=nombre_archivo)\n",
    "    plt.title(\"Forma de onda generada\")\n",
    "    plt.xlabel(\"Tiempo\")\n",
    "    plt.ylabel(\"Amplitud\")\n",
    "    plt.legend()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de señales a partir de las componentes frecuenciales de la imagen\n",
    "\n",
    "fs = 44100\n",
    "for nombre_archivo in os.listdir(\"images\"):\n",
    "    if nombre_archivo.endswith(('.png', '.jpg', '.JPG')):\n",
    "        ruta_imagen = os.path.join(\"images\", nombre_archivo)\n",
    "        procesar_imagen_fft(ruta_imagen, fs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
