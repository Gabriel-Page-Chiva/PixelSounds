{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto PixelSounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scipy.fftpack as fft\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d, median_filter\n",
    "from scipy import signal\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    import vozyaudio as vz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformada de Fourier en una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_imagen_fft(ruta_imagen, fs, N=50,duracion=5):\n",
    "    \n",
    "    # Se lee y se aplana la imagen se pasa a gris para q los valores sean de 0 a 255\n",
    "    imagen = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "    imagen = cv2.resize(imagen, (256, 256))\n",
    "    valores_pixeles = imagen.flatten()\n",
    "    \n",
    "    # Se aplica la transformada de fourier para obtener las frecuencias (gracias Victor)\n",
    "    espectro = np.abs(fft.fft(valores_pixeles))\n",
    "    freqs = fft.fftfreq(len(valores_pixeles), d=1/fs)\n",
    "    \n",
    "    # se eliminan las frecuencias negativas\n",
    "    freqs = freqs[freqs > 0]\n",
    "    espectro = espectro[:len(freqs)]\n",
    "    \n",
    "    # se sacan las frecuencias principales\n",
    "    indices_principales = np.argsort(espectro)[-N:]\n",
    "    freqs_principales = freqs[indices_principales]\n",
    "    \n",
    "    # Se genera la se침al de audio, se hace asi por la funcion de voz \n",
    "    t = np.linspace(0, duracion, int(fs * duracion), endpoint=False)\n",
    "    audio = np.zeros_like(t)\n",
    "    \n",
    "    for f in freqs_principales:\n",
    "        audio += np.sin(2 * np.pi * f * t)\n",
    "    \n",
    "    # se normaliza la se침al\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    \n",
    "    vz.sonido(audio, fs)\n",
    "    \n",
    "    plt.plot(t[:1000], audio[:1000],label=nombre_archivo)\n",
    "    plt.title(\"Forma de onda generada\")\n",
    "    plt.xlabel(\"Tiempo\")\n",
    "    plt.ylabel(\"Amplitud\")\n",
    "    plt.legend()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaci칩n de se침ales a partir de las componentes frecuenciales de la imagen\n",
    "\n",
    "fs = 44100\n",
    "for nombre_archivo in os.listdir(\"images\"):\n",
    "    if nombre_archivo.endswith(('.png', '.jpg', '.JPG')):\n",
    "        ruta_imagen = os.path.join(\"images\", nombre_archivo)\n",
    "        procesar_imagen_fft(ruta_imagen, fs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
