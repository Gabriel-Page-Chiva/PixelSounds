{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47389ef7",
   "metadata": {},
   "source": [
    "# PixelSounds: Visual Audio Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119b036",
   "metadata": {},
   "source": [
    "\n",
    "## Introducción: Codificación de Audio en Vídeo con PixelSounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c7086",
   "metadata": {},
   "source": [
    "\n",
    "PixelSounds es un sistema que convierte una señal de audio en un vídeo compuesto por frames. Cada frame codifica un bloque temporal del audio en forma de imagen, permitiendo visualizar la información sonora a través de representaciones visuales. El proceso es completamente reversible: se puede reconstruir el audio original a partir del vídeo.\n",
    "\n",
    "### Modos de codificación (`map_mode`)\n",
    "\n",
    "Cada bloque de audio se transforma en una fila de píxeles mediante uno de los siguientes modos:\n",
    "\n",
    "- **`ampl`**  \n",
    "  Codifica la amplitud normalizada del audio en una escala de grises.\n",
    "\n",
    "- **`fft`**  \n",
    "  Codifica el espectro en frecuencia (magnitud y fase) usando la Transformada Rápida de Fourier (FFT). Requiere codificar dos componentes por muestra.\n",
    "\n",
    "- **`fir`**  \n",
    "  Separa el audio en tres bandas de frecuencia (baja, media y alta) usando filtros FIR, y codifica cada banda en uno de los canales de color (R, G, B).\n",
    "\n",
    "### Modos de visualización (`color_mode`)\n",
    "\n",
    "Los frames generados pueden representarse en dos formas:\n",
    "\n",
    "- **`gris`**  \n",
    "  Las filas codificadas se replican verticalmente como una imagen monocroma. Este modo se usa, por ejemplo, para visualizar la amplitud o una sola banda.\n",
    "\n",
    "- **`color`**  \n",
    "  Se colorea cada muestra según su valor en los tres canales RGB, permitiendo ver diferentes componentes (por ejemplo, magnitud y fase, o bandas FIR) en diferentes colores.\n",
    "\n",
    "### Estructura del sistema\n",
    "\n",
    "- **Codificador:**  \n",
    "  Fragmenta el audio, aplica la codificación elegida y genera una secuencia de imágenes PNG. Luego empaqueta los frames en un vídeo MP4 usando FFmpeg.\n",
    "\n",
    "- **Decodificador:**  \n",
    "  Extrae los frames del vídeo, reconstruye los bloques de audio a partir de las imágenes, y aplica overlap-add para recuperar la señal completa.\n",
    "\n",
    "Este sistema permite experimentar con distintas formas de representar el contenido sonoro de una señal de audio, así como aplicar técnicas de visualización y análisis sobre los vídeos generados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8f30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "from scipy.signal import firwin, lfilter, get_window\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.io import wavfile as wav\n",
    "from IPython.display import Audio, Video, display\n",
    "\n",
    "from vozyaudio import lee_audio, sonido\n",
    "from funciones_rick import PixelSoundsEncoder, PixelSoundsDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4add8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in (\"fotogramas\", \"exports\"):\n",
    "    if os.path.exists(d):\n",
    "        print(f\"Eliminando carpeta existente: {d}/\")\n",
    "        shutil.rmtree(d)\n",
    "    else:\n",
    "        print(f\"No existe: {d}/ — nada que borrar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ad338",
   "metadata": {},
   "source": [
    "## 1. Carga de audio\n",
    "\n",
    "Cargamos un WAV de ejemplo y mostramos sus primeros segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6779b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"audios\\music.wav\"\n",
    "\n",
    "fs, orig = lee_audio(audio_path)\n",
    "print(f\"Frecuencia de muestreo: {fs} Hz\")\n",
    "Audio(orig, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f25c2",
   "metadata": {},
   "source": [
    "## 2. Definición de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ec646",
   "metadata": {},
   "source": [
    "### Relación entre FPS y FS en PixelSounds\n",
    "\n",
    "Una parte clave del sistema PixelSounds es la relación entre la frecuencia de muestreo del audio (`fs`) y los fotogramas por segundo (`fps`) del vídeo generado. Esta relación determina cómo se divide la señal de audio en bloques temporales y, por tanto, qué resolución temporal tendrá la visualización.\n",
    "\n",
    "#### Conversión audio → vídeo\n",
    "\n",
    "- El audio original tiene una frecuencia de muestreo `fs` (por ejemplo, 44100 Hz).\n",
    "- El vídeo tendrá `fps` (por ejemplo, 60 fotogramas por segundo).\n",
    "- Cada frame del vídeo representará un bloque de **N = fs / fps** muestras de audio.\n",
    "\n",
    "> Por ejemplo, si `fs = 44100` Hz y `fps = 60`, entonces `N = 735`.  \n",
    "> Esto significa que cada fotograma representa 735 muestras de audio, es decir, 735 / 44100 = 0.0166 segundos ≈ 16.6 ms de sonido.\n",
    "\n",
    "#### Ventaneo y solapamiento\n",
    "\n",
    "- Para evitar discontinuidades, se utiliza un solapamiento entre bloques con salto `hop = N // 2` (solapamiento del 50%).\n",
    "- Cada bloque se multiplica por una ventana (por ejemplo, tipo `hann`) antes de ser codificado para minimizar artefactos.\n",
    "\n",
    "#### Efecto visual y auditivo\n",
    "\n",
    "- Un valor alto de `fps` produce más frames por segundo y, por tanto, bloques de audio más pequeños (mayor resolución temporal, más precisión visual).\n",
    "- Un valor bajo de `fps` produce menos frames por segundo y bloques más grandes (más eficiencia, pero menor detalle en la visualización).\n",
    "\n",
    "> Es crucial mantener `fs` y `fps` constantes durante todo el proceso para asegurar que la reconstrucción del audio a partir del vídeo sea coherente y sin errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beca664",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps         = 60\n",
    "window_type = \"hann\"  # otras opciones: \"hamming\", \"blackman\", \"bartlett\", \"kaiser\", \"boxcar\", \"triang\", \"nuttall\", \"flattop\", \"parzen\", \"bohman\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddbb48",
   "metadata": {},
   "source": [
    "## 3. Modo Amplitude (`ampl`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5789529",
   "metadata": {},
   "source": [
    "\n",
    "### Codificación\n",
    "\n",
    "- **Bloque y ventana**  \n",
    "  Se extrae un fragmento de \\( N \\) muestras del audio y se aplica una ventana (por ejemplo, Hann) para evitar discontinuidades en los bordes.\n",
    "\n",
    "- **Normalización a [0–1]**  \n",
    "  $$\n",
    "  \\text{norm} = \\frac{\\text{block} - \\min(\\text{block})}{\\max(\\text{block}) - \\min(\\text{block}) + \\varepsilon}\n",
    "  $$  \n",
    "  Esto asegura que la amplitud mínima del bloque mapee a 0 y la máxima a 1.\n",
    "\n",
    "- **Cuantización a 8 bits**  \n",
    "  $$\n",
    "  \\text{fila}_i = \\lfloor \\text{norm}_i \\times 255 \\rfloor \\quad \\text{con} \\quad 0 \\leq \\text{fila}_i \\leq 255\n",
    "  $$\n",
    "\n",
    "- **Construcción de la imagen**  \n",
    "  - **Escala de grises**: se replica la misma fila de \\( N \\) píxeles en cada una de las \\( N \\) filas del PNG, resultando en una imagen uniforme.\n",
    "  - **Modo color**:  \n",
    "    $$\n",
    "    R = \\text{amplitud}, \\quad G = 255 - \\text{amplitud}, \\quad B = 128\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1292a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Generar → Empaquetar → Decodificar para ampl (gris y color)\n",
    "map_mode = \"ampl\"\n",
    "for color in (\"gris\", \"color\"):\n",
    "    # 3.1.1 Carpetas de salida\n",
    "    frames_dir = f\"fotogramas/{map_mode}_{color}_fotogramas\"\n",
    "    export_dir = f\"exports/{map_mode}_{color}\"\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    # 3.1.2 CODIFICAR\n",
    "    enc = PixelSoundsEncoder(\n",
    "        audio_path=audio_path,\n",
    "        frames_dir=frames_dir,\n",
    "        export_dir=export_dir,\n",
    "        fps=fps,\n",
    "        color_mode=color,\n",
    "        map_mode=map_mode,\n",
    "        window_type=window_type\n",
    "    )\n",
    "    enc.generate_frames()\n",
    "\n",
    "    # 3.1.3 EMPAQUETAR VÍDEO\n",
    "    video_file = enc.encode_video()\n",
    "    print(f\"[Notebook] Vídeo generado en: {video_file}\")\n",
    "    display(Video(video_file, embed=True, width=480, height=360))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87598b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### Decodificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d75614f",
   "metadata": {},
   "source": [
    "\n",
    "- **Lectura de píxeles**  \n",
    "  Se carga el PNG y se extrae la fila 0:  \n",
    "  - En gris → valor único por píxel  \n",
    "  - En color → canal Rojo\n",
    "\n",
    "- **Desnormalización a [0–1]**  \n",
    "  $$\n",
    "  \\text{amp} = \\frac{\\text{pixel}}{255}\n",
    "  $$\n",
    "\n",
    "- **Recuperar bipolaridad [–1 … +1]**  \n",
    "  $$\n",
    "  \\text{block}_i = \\text{amp}_i \\times 2 - 1\n",
    "  $$\n",
    "\n",
    "- **Overlap-add con ventana**  \n",
    "  Cada bloque reconstruido se solapa a la mitad (hop = \\( N/2 \\)) y se suma usando la misma ventana, recomponiendo la señal continua.\n",
    "\n",
    "- **Normalización final**  \n",
    "  $$\n",
    "  \\text{audio}[t] \\mathrel{{/}{=}} \\sum \\text{ventana}\n",
    "  $$\n",
    "\n",
    "El resultado es un archivo `.wav` cuya forma de onda sigue fielmente la envolvente original, con las únicas pérdidas debidas a la cuantización a 8 bits y al solapamiento de ventanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_mode = \"ampl\"\n",
    "base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "\n",
    "for color in (\"gris\", \"color\"):\n",
    "    # 1) Directorios y rutas\n",
    "    frames_dir = f\"fotogramas/{map_mode}_{color}_fotogramas\"\n",
    "    export_dir = f\"exports/{map_mode}_{color}\"\n",
    "    # Nombre del vídeo que acabamos de generar\n",
    "    video_file = os.path.join(export_dir, f\"{base_name}_{map_mode}_{color}.mp4\")\n",
    "    # Fichero WAV de salida\n",
    "    output_wav = os.path.join(export_dir, f\"recon_{base_name}_{map_mode}_{color}.wav\")\n",
    "    \n",
    "    # 2) Instanciar decoder\n",
    "    dec = PixelSoundsDecoder(\n",
    "        frames_dir=frames_dir, # Donde guardar los frames extraidos\n",
    "        output_wav=output_wav, # Video del que sacar los frames\n",
    "        map_mode=map_mode,     # Modo\n",
    "        window_type=window_type # Tipo de ventana\n",
    "    )\n",
    "    \n",
    "    # 3) Extraer frames desde el MP4\n",
    "    dec.extract_all_frames(video_file)\n",
    "    \n",
    "    # 4) Reconstruir el audio y guardarlo\n",
    "    audio_rec, fs_rec = dec.decode()\n",
    "    \n",
    "    # 5) Mostrar y reproducir inline\n",
    "    print(f\"[Notebook] Audio reconstruido ({map_mode}_{color}):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505d052",
   "metadata": {},
   "source": [
    "## 4. Modo FFT (`fft`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b18614",
   "metadata": {},
   "source": [
    "\n",
    "### Codificación\n",
    "\n",
    "- **Transformada de Fourier (FFT)**  \n",
    "  Se aplica una FFT al bloque de audio con longitud \\( N \\) y se centra el espectro usando un `fftshift`.\n",
    "\n",
    "  $$\n",
    "  X = \\text{fftshift}\\left( \\text{FFT}(\\text{block}) \\right)\n",
    "  $$\n",
    "\n",
    "- **Extracción de magnitud y fase**  \n",
    "  $$\n",
    "  \\text{mag} = |X| \\qquad \\text{phase} = \\angle X\n",
    "  $$\n",
    "\n",
    "- **Normalización a enteros sin signo de 8 bits**  \n",
    "  - Magnitud:\n",
    "\n",
    "    $$\n",
    "    \\text{mag}_n = \\left\\lfloor \\frac{\\text{mag}}{\\max(\\text{mag}) + \\varepsilon} \\times 255 \\right\\rfloor\n",
    "    $$\n",
    "\n",
    "  - Fase (rango [\\(-\\pi\\), \\(+\\pi\\)] → [0, 255]):\n",
    "\n",
    "    $$\n",
    "    \\text{phase}_n = \\left\\lfloor \\frac{\\text{phase} + \\pi}{2\\pi} \\times 255 \\right\\rfloor\n",
    "    $$\n",
    "\n",
    "- **Construcción de la imagen**  \n",
    "  - **Escala de grises**:  \n",
    "    Se intercalan las filas de magnitud y fase:\n",
    "\n",
    "    $$\n",
    "    \\text{img}_{2k} = \\text{mag}_n \\quad , \\quad \\text{img}_{2k+1} = \\text{phase}_n\n",
    "    $$\n",
    "\n",
    "  - **Modo color**:  \n",
    "    Se asigna:\n",
    "\n",
    "    $$\n",
    "    R = \\text{mag}_n, \\quad G = \\text{phase}_n, \\quad B = 255\n",
    "    $$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Generar → Empaquetar → Decodificar para FFT (gris y color)\n",
    "map_mode = \"fft\"\n",
    "for color in (\"gris\", \"color\"):\n",
    "    # 3.1.1 Carpetas de salida\n",
    "    frames_dir = f\"fotogramas/{map_mode}_{color}_fotogramas\"\n",
    "    export_dir = f\"exports/{map_mode}_{color}\"\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    # 3.1.2 CODIFICAR\n",
    "    enc = PixelSoundsEncoder(\n",
    "        audio_path=audio_path,\n",
    "        frames_dir=frames_dir,\n",
    "        export_dir=export_dir,\n",
    "        fps=fps,\n",
    "        color_mode=color,\n",
    "        map_mode=map_mode,\n",
    "        window_type=window_type\n",
    "    )\n",
    "    enc.generate_frames()\n",
    "\n",
    "    # 3.1.3 EMPAQUETAR VÍDEO\n",
    "    video_file = enc.encode_video()\n",
    "    print(f\"[Notebook] Vídeo generado en: {video_file}\")\n",
    "    # display(Video(video_file, embed=True, width=480, height=360))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e50812",
   "metadata": {},
   "source": [
    "### Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ff169",
   "metadata": {},
   "source": [
    "\n",
    "Los vídeos generados en modo **FFT** suelen ser muy grandes y a veces el notebook tarda o se “congela” al intentar renderizarlos inline. Por ello **no recomendamos** ejecutar la celda de abajo en el notebook si ves que no responde. \n",
    "\n",
    "> **Sugerencia**:  \n",
    "> - Abre el fichero MP4 directamente en **VLC** o **VSCode**  \n",
    "> - O puedes reproducirlos en un navegador externo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "\n",
    "for map_mode, color in [(\"fft\", \"gris\"), (\"fft\", \"color\")]:\n",
    "    video_file = os.path.join(\n",
    "        \"exports\",\n",
    "        f\"{map_mode}_{color}\",\n",
    "        f\"{base}_{map_mode}_{color}.mp4\"\n",
    "    )\n",
    "    print(f\"Vídeo FFT ({map_mode}_{color}): {video_file}\")\n",
    "    # DESCOMENTA la siguiente si quieres intentarlo (no lo recomendamos ) \n",
    "    # display(Video(video_file, embed=True, width=480, height=360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74d851",
   "metadata": {},
   "source": [
    "### Decodificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2e00aa",
   "metadata": {},
   "source": [
    "- **Lectura de magnitud y fase**  \n",
    "  - En modo color se toman los canales R y G.  \n",
    "  - En modo gris se extraen de las filas 0 (magnitud) y 1 (fase).\n",
    "\n",
    "- **Desnormalización de magnitud y fase**  \n",
    "  $$\n",
    "  \\text{mag} = \\frac{\\text{mag}_n}{255}, \\qquad \\text{phase} = \\frac{\\text{phase}_n}{255} \\times 2\\pi - \\pi\n",
    "  $$\n",
    "\n",
    "- **Reconstrucción del espectro complejo**  \n",
    "  $$\n",
    "  X = \\text{mag} \\cdot e^{j \\cdot \\text{phase}}\n",
    "  $$\n",
    "\n",
    "- **Transformada inversa y desfase de espectro**  \n",
    "  $$\n",
    "  X = \\text{ifftshift}(X), \\quad \\text{block} = \\text{Re}\\left( \\text{IFFT}(X) \\right)\n",
    "  $$\n",
    "\n",
    "- **Solapamiento y normalización**  \n",
    "  Se aplica overlap-add con ventana y se normaliza por los pesos acumulados, como en los otros modos.\n",
    "\n",
    "El modo `fft` permite recuperar tanto el contenido espectral como la fase del bloque, generando reconstrucciones más fieles pero a costa de mayor complejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_mode = \"fft\"\n",
    "base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "\n",
    "for color in (\"gris\", \"color\"):\n",
    "    # 1) Directorios y rutas\n",
    "    frames_dir = f\"fotogramas/{map_mode}_{color}_fotogramas\"\n",
    "    export_dir = f\"exports/{map_mode}_{color}\"\n",
    "    # Nombre del vídeo que acabamos de generar\n",
    "    video_file = os.path.join(export_dir, f\"{base_name}_{map_mode}_{color}.mp4\")\n",
    "    # Fichero WAV de salida\n",
    "    output_wav = os.path.join(export_dir, f\"recon_{base_name}_{map_mode}_{color}.wav\")\n",
    "    \n",
    "    # 2) Instanciar decoder\n",
    "    dec = PixelSoundsDecoder(\n",
    "        frames_dir=frames_dir, # Donde guardar los frames extraidos\n",
    "        output_wav=output_wav, # Video del que sacar los frames\n",
    "        map_mode=map_mode,     # Modo\n",
    "        window_type=window_type # Tipo de ventana\n",
    "    )\n",
    "    \n",
    "    # 3) Extraer frames desde el MP4\n",
    "    dec.extract_all_frames(video_file)\n",
    "    \n",
    "    # 4) Reconstruir el audio y guardarlo\n",
    "    audio_rec, fs_rec = dec.decode()\n",
    "    \n",
    "    # 5) Mostrar y reproducir inline\n",
    "    print(f\"[Notebook] Audio reconstruido ({map_mode}_{color}):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8c15f",
   "metadata": {},
   "source": [
    "## 5. Modo FIR (`fir`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64627b0",
   "metadata": {},
   "source": [
    "\n",
    "#### Codificación\n",
    "\n",
    "- **Filtrado en tres bandas**  \n",
    "  Se aplica un banco de filtros FIR al bloque:\n",
    "\n",
    "  $$\n",
    "  y_L = \\text{lfilter}(b_{\\text{low}}, 1, \\text{block}) \\\\\n",
    "  y_B = \\text{lfilter}(b_{\\text{band}}, 1, \\text{block}) \\\\\n",
    "  y_H = \\text{lfilter}(b_{\\text{high}}, 1, \\text{block})\n",
    "  $$\n",
    "\n",
    "- **Clipping y cuantificación a enteros de 8 bits con signo**  \n",
    "  Se limita cada banda al rango \\([-1, +1]\\) y se escala a 8 bits con signo:\n",
    "\n",
    "  $$\n",
    "  r = \\left\\lfloor y_L \\cdot 127 \\right\\rfloor, \\quad\n",
    "  g = \\left\\lfloor y_B \\cdot 127 \\right\\rfloor, \\quad\n",
    "  b = \\left\\lfloor y_H \\cdot 127 \\right\\rfloor\n",
    "  $$\n",
    "\n",
    "  Posteriormente se reinterpretan como `uint8` para almacenarlos en la imagen:\n",
    "\n",
    "  $$\n",
    "  r_8 = \\text{reinterpretar como uint8}(r), \\quad \\text{etc.}\n",
    "  $$\n",
    "\n",
    "- **Construcción de la imagen**  \n",
    "  - **Modo color**:  \n",
    "    Se construye un frame RGB directamente con los canales \\((r_8, g_8, b_8)\\).\n",
    "\n",
    "  - **Modo gris**:  \n",
    "    Se intercalan las tres bandas en las filas de la imagen:\n",
    "\n",
    "    $$\n",
    "    \\text{img}_{3k} = r_8, \\quad \\text{img}_{3k+1} = g_8, \\quad \\text{img}_{3k+2} = b_8\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Generar → Empaquetar → Decodificar para FFT (gris y color)\n",
    "map_mode = \"fir\"\n",
    "for color in (\"gris\", \"color\"):\n",
    "    # 3.1.1 Carpetas de salida\n",
    "    frames_dir = f\"fotogramas/{map_mode}_{color}_fotogramas\"\n",
    "    export_dir = f\"exports/{map_mode}_{color}\"\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    # 3.1.2 CODIFICAR\n",
    "    enc = PixelSoundsEncoder(\n",
    "        audio_path=audio_path,\n",
    "        frames_dir=frames_dir,\n",
    "        export_dir=export_dir,\n",
    "        fps=fps,\n",
    "        color_mode=color,\n",
    "        map_mode=map_mode,\n",
    "        window_type=window_type\n",
    "    )\n",
    "    enc.generate_frames()\n",
    "\n",
    "    # 3.1.3 EMPAQUETAR VÍDEO\n",
    "    video_file = enc.encode_video()\n",
    "    print(f\"[Notebook] Vídeo generado en: {video_file}\")\n",
    "    display(Video(video_file, embed=True, width=480, height=360))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8154f6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Decodificación\n",
    "\n",
    "- **Extracción de las bandas**  \n",
    "  - En **modo color**:\n",
    "\n",
    "    $$\n",
    "    y_L = \\text{reinterpretar como int8}(R) / 127 \\\\\n",
    "    y_B = \\text{reinterpretar como int8}(G) / 127 \\\\\n",
    "    y_H = \\text{reinterpretar como int8}(B) / 127\n",
    "    $$\n",
    "\n",
    "  - En **modo gris**:\n",
    "\n",
    "    $$\n",
    "    y_L = \\text{reinterpretar como int8}(\\text{fila }0::3) / 127 \\\\\n",
    "    y_B = \\text{reinterpretar como int8}(\\text{fila }1::3) / 127 \\\\\n",
    "    y_H = \\text{reinterpretar como int8}(\\text{fila }2::3) / 127\n",
    "    $$\n",
    "\n",
    "- **Suma de las bandas**  \n",
    "  Se combinan las tres bandas para reconstruir el bloque:\n",
    "\n",
    "  $$\n",
    "  \\text{block} = y_L + y_B + y_H\n",
    "  $$\n",
    "\n",
    "- **Solapamiento y reconstrucción final**  \n",
    "  Se hace overlap-add y normalización con la ventana, como en los otros modos.\n",
    "\n",
    "  Este modo es útil para representar la energía en distintas bandas del espectro, con menor fidelidad que `fft` pero menor tamaño y buena separación frecuencial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_mode = \"fir\"\n",
    "base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "\n",
    "for color in (\"gris\", \"color\"):\n",
    "    # 1) Directorios y rutas\n",
    "    frames_dir = f\"fotogramas/{map_mode}_{color}_fotogramas\"\n",
    "    export_dir = f\"exports/{map_mode}_{color}\"\n",
    "    # Nombre del vídeo que acabamos de generar\n",
    "    video_file = os.path.join(export_dir, f\"{base_name}_{map_mode}_{color}.mp4\")\n",
    "    # Fichero WAV de salida\n",
    "    output_wav = os.path.join(export_dir, f\"recon_{base_name}_{map_mode}_{color}.wav\")\n",
    "    \n",
    "    # 2) Instanciar decoder\n",
    "    dec = PixelSoundsDecoder(\n",
    "        frames_dir=frames_dir, # Donde guardar los frames extraidos\n",
    "        output_wav=output_wav, # Video del que sacar los frames\n",
    "        map_mode=map_mode,     # Modo\n",
    "        window_type=window_type # Tipo de ventana\n",
    "    )\n",
    "    \n",
    "    # 3) Extraer frames desde el MP4\n",
    "    dec.extract_all_frames(video_file)\n",
    "    \n",
    "    # 4) Reconstruir el audio y guardarlo\n",
    "    audio_rec, fs_rec = dec.decode()\n",
    "    \n",
    "    # 5) Mostrar y reproducir inline\n",
    "    print(f\"[Notebook] Audio reconstruido ({map_mode}_{color}):\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Voz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
